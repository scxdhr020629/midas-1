import sys
import torch
import torch.nn as nn
import numpy as np
from model_1 import AttnFusionGCNNet  # <-- [‰øÆÊîπ] ÂØºÂÖ•Êñ∞Ê®°Âûã
from utils import *
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, roc_curve
from torch_geometric.data import DataLoader
import os
import optuna  # ÂØºÂÖ• Optuna
import time

# --- ÂÖ®Â±ÄÂ∏∏Èáè ---
LOG_INTERVAL = 45
NUM_FOLDS = 5
loss_fn = nn.BCELoss()


# ============================================================================
#
# Ê†∏ÂøÉËÆ≠ÁªÉ/È¢ÑÊµãÂáΩÊï∞
#
# ============================================================================

def train(model, device, train_loader, optimizer, epoch):
    """ËÆ≠ÁªÉ‰∏Ä‰∏™epoch"""
    # print('Training on {} samples...'.format(len(train_loader.dataset))) # Âú®‰ºòÂåñÊó∂Â§™Âêµ
    model.train()
    for batch_idx, data in enumerate(train_loader):
        optimizer.zero_grad()
        data = data.to(device)
        output = model(data)
        labels = data.y.view(-1, 1).float().to(device)

        if torch.isnan(output).any():
            print(f"\n[!!! Ëá¥ÂëΩÈîôËØØÔºöÊ®°ÂûãËæìÂá∫ NaN !!!]")
            raise ValueError("Model output is NaN. Stopping training.")

        epsilon = 1e-7
        output_clamped = torch.clamp(output, min=epsilon, max=1.0 - epsilon)

        if labels.min() < 0.0 or labels.max() > 1.0:
            print(f"\n[!!! Ëá¥ÂëΩÈîôËØØÔºöÊ†áÁ≠æË∂äÁïå !!!]")
            raise ValueError("Labels out of bounds for BCELoss. Check your data.")

        loss = loss_fn(output_clamped, labels)

        if torch.isnan(loss):
            print(f"\n[!!! Ëá¥ÂëΩÈîôËØØÔºöÊçüÂ§±(Loss)‰∏∫ NaN !!!]")
            raise ValueError("Loss is NaN. Stopping training.")

        loss.backward()
        optimizer.step()


def predicting(model, device, loader):
    """È¢ÑÊµãÂáΩÊï∞ - Âè™ËøîÂõûÊåáÊ†á"""
    model.eval()
    total_probs = []
    total_labels = []

    with torch.no_grad():
        for data in loader:
            data = data.to(device)
            output = model(data)
            probs = output.cpu().numpy()
            total_probs.extend(probs)
            total_labels.extend(data.y.view(-1, 1).cpu().numpy())

    total_probs = np.array(total_probs).flatten()
    total_labels = np.array(total_labels).flatten()
    total_preds = (total_probs >= 0.5).astype(int)

    accuracy = accuracy_score(total_labels, total_preds)
    precision = precision_score(total_labels, total_preds, zero_division=0)
    recall = recall_score(total_labels, total_preds, zero_division=0)
    f1 = f1_score(total_labels, total_preds, zero_division=0)

    try:
        roc_auc = roc_auc_score(total_labels, total_probs)
    except ValueError:
        roc_auc = 0.5

    precision_vals, recall_vals, _ = precision_recall_curve(total_labels, total_probs)
    pr_auc = auc(recall_vals, precision_vals)

    return accuracy, precision, recall, f1, roc_auc, pr_auc


# ============================================================================
#
# 5-Fold CV ËÆ≠ÁªÉÂáΩÊï∞
#
# ============================================================================

def run_cv_training(params, device, trial=None):  # <-- [‰øÆÊîπ] ÁßªÈô§ ablation_mode
    """
    ËøêË°åÂÆåÊï¥ÁöÑ 5-Fold ‰∫§ÂèâÈ™åËØÅ (Êó†ÁªòÂõæ)
    """

    # ‰ªé params Â≠óÂÖ∏‰∏≠Ëß£ÂåÖË∂ÖÂèÇÊï∞
    LR = params["lr"]
    NUM_EPOCHS = params["num_epochs"]
    TRAIN_BATCH_SIZE = params["batch_size"]
    TEST_BATCH_SIZE = params["batch_size"]
    WEIGHT_DECAY = params["weight_decay"]

    # TODO: ‰ªé params ‰∏≠Ëß£ÂåÖ‰Ω†Ê®°ÂûãÁöÑË∂ÖÂèÇÊï∞
    # ‰æãÂ¶Ç:
    # HIDDEN_DIM = params["hidden_dim"]
    # DROPOUT_RATE = params["dropout_rate"]

    accuracies = []
    precisions = []
    recalls = []
    f1_scores = []
    roc_aucs = []
    pr_aucs = []

    modeling = AttnFusionGCNNet  # <-- [‰øÆÊîπ] ‰ΩøÁî®Êñ∞Ê®°Âûã

    for fold in range(NUM_FOLDS):
        train_data = TestbedDataset(root='data', dataset='train' + str(fold))
        test_data = TestbedDataset(root='data', dataset='test' + str(fold))
        train_loader = DataLoader(train_data, batch_size=TRAIN_BATCH_SIZE, shuffle=True, drop_last=True)
        test_loader = DataLoader(test_data, batch_size=TEST_BATCH_SIZE, shuffle=False, drop_last=True)

        # ÂàùÂßãÂåñÊ®°Âûã
        # TODO: Â∞ÜÊ®°ÂûãÁöÑË∂ÖÂèÇÊï∞‰º†ÂÖ•ÊûÑÈÄ†ÂáΩÊï∞
        model = modeling(
            # hidden_dim=HIDDEN_DIM,
            # dropout_rate=DROPOUT_RATE
        ).to(device)

        optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)

        for epoch in range(NUM_EPOCHS):
            train(model, device, train_loader, optimizer, epoch + 1)

        accuracy, precision, recall, f1, roc_auc, pr_auc = predicting(model, device, test_loader)

        accuracies.append(accuracy)
        precisions.append(precision)
        recalls.append(recall)
        f1_scores.append(f1)
        roc_aucs.append(roc_auc)
        pr_aucs.append(pr_auc)

        if trial:
            trial.report(pr_auc, fold)
            if trial.should_prune():
                raise optuna.exceptions.TrialPruned()

    avg_pr_auc = np.mean(pr_aucs)

    return avg_pr_auc


# ============================================================================
#
# Optuna Objective Function
#
# ============================================================================

def objective(trial, device):  # <-- [‰øÆÊîπ] ÁßªÈô§ ablation_mode
    """Optuna ÁöÑ Objective ÂáΩÊï∞"""

    # 1. ÂÆö‰πâË∂ÖÂèÇÊï∞ÁöÑÊêúÁ¥¢Á©∫Èó¥
    params = {
        "lr": trial.suggest_float("lr", 1e-5, 1e-2, log=True),
        "weight_decay": trial.suggest_float("weight_decay", 1e-6, 1e-2, log=True),
        "batch_size": trial.suggest_categorical("batch_size", [64, 128, 256]),
        "num_epochs": trial.suggest_int("num_epochs", 20, 70)

        # TODO: Âú®ËøôÈáåÊ∑ªÂä†‰Ω†ÁöÑÊ®°ÂûãË∂ÖÂèÇÊï∞
        # "hidden_dim": trial.suggest_categorical("hidden_dim", [64, 128, 256]),
        # "dropout_rate": trial.suggest_float("dropout_rate", 0.1, 0.5),
        # "num_layers": trial.suggest_int("num_layers", 2, 5),
    }

    # 2. ËøêË°å 5-Fold CV Âπ∂Ëé∑Âèñ
    try:
        avg_pr_auc = run_cv_training(
            params=params,
            device=device,
            trial=trial
        )
        return avg_pr_auc

    except optuna.exceptions.TrialPruned as e:
        raise e
    except Exception as e:
        print(f"[!!! Trial Â§±Ë¥• !!!] ID: {trial.number}, Params: {trial.params}")
        print(f"  Error: {e}")
        # Âú®Â†ÜÊ†àË∑üË∏™‰∏≠ÊâìÂç∞Êõ¥ËØ¶ÁªÜÁöÑÈîôËØØ
        import traceback
        traceback.print_exc()
        return -1.0

    # ============================================================================


#
# Main Execution
#
# ============================================================================

if __name__ == "__main__":

    # --- 1. Âü∫Êú¨ËÆæÁΩÆ ---
    cuda_name = "cuda:0"
    if len(sys.argv) > 1:
        cuda_name = "cuda:" + str(int(sys.argv[1]))
    print('cuda_name:', cuda_name)

    # (ÁßªÈô§‰∫Ü ablation_mode)
    # ablation_mode = sys.argv[2] if len(sys.argv) > 2 else 'baseline'
    # print(f"Ablation mode: {ablation_mode}")

    device = torch.device(cuda_name if torch.cuda.is_available() else "cpu")
    print(f'Using device: {device}\n')

    # --- 2. Optuna Study ËÆæÁΩÆ ---

    # [‰øÆÊîπ] ÁÆÄÂåñ‰∫Ü study ÂêçÁß∞
    storage_name = f"sqlite:///optuna_study.db"
    study_name = f"optimization_attn_model"

    print(f"Optuna study storage: {storage_name}")
    print(f"Optuna study name: {study_name}")

    study = optuna.create_study(
        direction="maximize",
        storage=storage_name,
        study_name=study_name,
        load_if_exists=True,
        pruner=optuna.pruners.MedianPruner(n_warmup_steps=1)
    )

    # --- 3. ËøêË°å‰ºòÂåñ ---
    N_TRIALS = 50

    print(f"\nStarting Optuna optimization for '{study_name}'...")
    print(f"Running {N_TRIALS} new trials (Total trials will be {len(study.trials) + N_TRIALS}).")

    start_time = time.time()
    study.optimize(
        lambda trial: objective(trial, device),  # <-- [‰øÆÊîπ] ÁßªÈô§ ablation_mode
        n_trials=N_TRIALS,
        timeout=60 * 60 * 4
    )
    end_time = time.time()

    print(f"\nOptimization finished in {(end_time - start_time) / 60:.2f} minutes.")

    # --- 4. ÊâìÂç∞‰ºòÂåñÁªìÊûú ---
    print("\n" + "=" * 70)
    print("Optimization Summary")
    print("=" * 70)
    print(f"Number of finished trials: {len(study.trials)}")

    try:
        best_trial = study.best_trial
        print("\nBest trial:")
        print(f"  Value (Max Avg PR-AUC): {best_trial.value:.6f}")

        print("\n  Best hyperparameters:")
        for key, value in best_trial.params.items():
            print(f"    {key}: {value}")
    except ValueError:
        print("\n[!!! ÈîôËØØ !!!] Êú™ÊâæÂà∞ÊúÄ‰Ω≥ËØïÈ™å„ÄÇ")
        print("ËøôÂèØËÉΩÊÑèÂë≥ÁùÄÊâÄÊúâËØïÈ™åÈÉΩÂ§±Ë¥•‰∫ÜÔºàËøîÂõû -1.0Ôºâ„ÄÇ")
        print("ËØ∑Ê£ÄÊü•‰∏äÈù¢ÊâìÂç∞ÁöÑ 'Trial Â§±Ë¥•' ÈîôËØØÊó•Âøó„ÄÇ")

    # --- 5. ÊúÄÁªàÊ≠•È™§ (ÁßªÈô§‰∫ÜÁªòÂõæ) ---
    print("\n" + "=" * 70)
    print(f"üéâ Bayesian optimization complete!")
    print(f"   Optuna study saved to '{storage_name}'")